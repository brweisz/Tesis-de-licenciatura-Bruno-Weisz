\documentclass[11pt,a4paper]{tesis}
\usepackage{minted}
\usepackage{amsmath}   
\usepackage{booktabs}  
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[left=3cm,right=3cm,bottom=3.5cm,top=3.5cm]{geometry}
\usepackage{float}
\usepackage{amssymb} 
\usepackage{url}
\usepackage{xcolor}
\usepackage{todonotes}
\usepackage{xspace}
\usepackage[hidelinks]{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{dirtree}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{subcaption}
\usetikzlibrary{arrows.meta, positioning}


\newcommand\zeroknowledge{\textbf{Zero Knowledge}\xspace}
\newcommand\zk{\textbf{ZK}\xspace}
\newtheorem{prop}{Propiedad}

\begin{document}

%%%% CARATULA

\def\autor{Bruno Weisz}
\def\tituloTesis{Demostrando la ejecución de un  \vspace{.2cm} \\ programa de alto nivel con Plonky2}
\def\runtitulo{Demostrando la correcta ejecución de un programa de alto nivel con Plonky2}
\def\runtitle{}
\def\director{Agustín Garassino}
\def\codirector{Matías López y Rosenfeld}
\def\lugar{Buenos Aires, 2025}
\input{caratula}

%%%% ABSTRACTS, AGRADECIMIENTOS Y DEDICATORIA
\frontmatter
\pagestyle{empty}
\input{abs_esp.tex}

% \input{abs_en.tex} % OPCIONAL: comentar si no se quiere

% \input{agradecimientos.tex} % OPCIONAL: comentar si no se quiere
\newpage
%\input{dedicatoria.tex}  % OPCIONAL: comentar si no se quiere
\newpage
\tableofcontents

\mainmatter
\pagestyle{headings}

%%%% ACA VA EL CONTENIDO DE LA TESIS

\part{Introducción}
\include{secciones/introduccion}
\include{secciones/primitivas_criptograficas}
\include{secciones/proving_systems}
\include{secciones/pcs.tex}
\include{secciones/problema_a_resolver}

\part{Desarrollo}
\include{secciones/noir}
\include{secciones/plonky2}
\include{secciones/noirky2}



\chapter{Evaluación de la herramienta}


\section{Validación con tests funcionales}\label{sec:tests}
Una parte crucial del proceso de desarrollo es validar a través de tests que la herramienta generada está cumpliendo con los requerimientos, sin embargo, en el contexto de los SNARKs y en particular con Plonky2 esto puede llegar a ser un desafío. Supongamos el siguiente escenario: Noirky2 recibe un código ACIR y un conjunto de witnesses como input y a partir de ellos crea un circuito en Plonky2, crea una prueba de este circuito con los valores de witnesses provistos y la verifica. Todo parece correcto, sin embargo, ¿Qué pasaría si la traducción de Noirky2 consistiera en hacer un circuito vacío que siempre verifica? Automáticamente cualquier programa generado debería verificar correctamente, sin embargo sabemos que la implementación no existe. 

Tratamos de solucionar este problema haciendo tests por la negativa, es decir, proveyendo datos de entrada a la generación de la prueba que no satisfacen el sistema de ecuaciones y viendo que la verificación falla. Sin embargo no fue la verificación la que falló, sino la generación de la prueba misma. La explicación de esto es que Plonky2 resuelve todos los valores de sus Targets (o variables del sistema de ecuaciones). Si un valor provisto como input para la prueba es distinto a un valor que el motor de Plonky2 resuelve, este va a fallar en tiempo de resolución de circuito, ya que se trató de asignar a una misma variable del sistema de ecuaciones 2 valores distintos en momentos diferentes. El hecho de que falle la generación de la prueba también es útil para validar que la herramienta está haciendo lo previsto, sin embargo esto deja de lado un problema de seguridad.

Plonky2 hace 2 cosas. Resuelve el valor de todos los Targets cuando genera la prueba y verifica que las restricciones polinomiales se cumplen cuando la verifica. Resolver el valor de los targets podemos pensarlo como ``llenar la traza'' (la matriz $T$) vista en la sección \ref{sec:plonk}. Sin embargo, estamos asumiendo que luego de que Plonky2 ``llena la traza'' ningún atacante la modifica, lo cual es potencialmente incorrecto. Lo bueno es que si modificamos la traza, luego la verificación debería fallar, asumiendo que establecimos todas las restricciones correctamente. Ese es el centro de la cuestión, ¿cómo validamos que las restricciones están establecidas correctamente? Para hacer eso tendríamos que hacer tests por la negativa, pero no como los anteriores, sino modificando la traza luego de que esta sea generada por Plonky2 y viendo que es la verificación (y no la generación de la prueba) la que falla.

El problema con esto es que Plonky2 no va a generar una traza incorrecta. La resolución de operaciones de Plonky2 está pensada para corresponderse con las ecuaciones que se intentan verificar. Por ejemplo, si se establece una restricción de la forma $t_3 = t_1 + t_2$ la resolución de targets de Plonky2 le va a asignar a $t_3$ el valor de $t_1 + t_2$. Si proveyéramos con valores inconsistentes a $t_1, t_2 \text{ y } t_3$ fallaría la generación de la prueba, pero nunca vamos a poder verificar que las restricciones están haciendo lo que nosotros queremos (o dicho con otras palabras, hacer que falle la verificación). 

Al mismo tiempo, hacer tests por la negativa del primer tipo (que fallan en la generación de la prueba) no es tan malo como suena. El sistema de resolución de Targets de Plonky2 va a fallar si detecta una desconexión en el circuito (targets que no están resueltos), lo cual valida cierto grado de consistencia en la construcción del circuito. Si a eso le sumamos que las herramientas que se están usando para construir el circuito son propias de la API de Plonky2 (\texttt{CircuitBuilder} y las Custom Gates preexistentes) en realidad lo que estamos diciendo es que la confianza en lo que estamos construyendo depende directamente de la confianza que tengamos en que las herramientas preexistentes validan correctamente las operaciones que hacen. 

Lo anterior no quita que no se puedan hacer tests adicionales para asegurar que se están verificando las operaciones, sin embargo la cantidad de trabajo requerido para intervenir la generación de la prueba de Plonky2 descarta esta alternativa en pos de un modelo de confianza más débil. 

Todos los tests usados para validar la funcionalidad pueden encontrarse en el repositorio del proyecto.

%https://github.com/eryxcoop/acvm-backend-plonky2/tree/main/plonky2-backend/src/circuit_translation/tests


\section{Profiling}\label{sec:materiales_y_metodos}
En la sección \ref{sec:problema} planteamos como último objetivo del trabajo hacer un reporte de performance de la herramienta creada. Sin embargo, decir que la performance está atada únicamente a Noirky2 sería incorrecto: recordemos que la herramienta no hace más que una adaptación de un lenguaje a otro. El procesamiento de cada prover (Plonky2 y Barretenberg) va a influir enormemente en la performance de los distintos comandos, así como en en el tamaño de los artefactos generados (prueba y verifying key).

Nos interesa evaluar ciertas familias de programas, cada una de ellas orientada a uno de los opcodes del código ACIR. Estas familias de programas son: 
\begin{enumerate}
    \item Orientada a AssertZero.
    \item Orientada a operaciones de memoria.
    \item Orientada a RangeCheck.
    \item Orientadas a XOR.
\end{enumerate}

Por cada una de ellas queremos variar el tamaño de los programas. Esto quiere decir que queremos generar códigos ACIR que posean \textbf{distintas cantidades de opcodes}. \texttt{N} es la meta-variable que vamos a usar en los templates de Noir para parametrizar estas cantidades. A su vez, para los programas orientados a RangeCheck y XOR también nos interesa variar la cantidad de bits de las operaciones, siendo las posibles variantes 8, 16 y 32 bits. Esta variación será parametrizada con la meta-variable \texttt{K}. 

\subsubsection{\textbf{Programas orientados a AssertZero}}
El template de programa utilizado es el que se puede ver en el programa de Noir \ref{lst:familia_assert_zero}.
\begin{center}
\begin{minipage}{0.6\textwidth}
\begin{minted}[frame=single, framesep=10pt, bgcolor=white]{rust}
fn main(a: [Field; N]) -> pub Field {
    let mut acc: Field = 0;
    for i in 0..N {
        acc += a[i];
        acc *= a[i];
    }
    acc
}
\end{minted}
\captionof{listing}{Familia de programas orientada a AssertZero}
\label{lst:familia_assert_zero}
\end{minipage}
\end{center}

Este programa recibe como input una lista de $N$ elementos de cuerpo y luego toma una variable \texttt{acc} para acumular valores. La intención con este programa es generar muchas operaciones de tipo AssertZero, como veremos a continuación. Más en general, la idea es crear programas a partir del template con distintos valores de $N$. Al compilar esos programas de Noir, el código ACIR generado tendrá $N$ opcodes AssertZero que usen términos lineales y cuadtráticos, de la forma 

$$(1 \cdot w_0 \cdot w_1) + (1 \cdot w_2) + (-1 \cdot w_3) = 0 $$

La forma del programa es relativamente arbitraria, su único objetivo es generar la cantidad adecuada de opcodes AssertZero con la forma deseada. A su vez, los inputs para cada programa serán $N$ valores aleatorios en el rango $[0,p)$, donde usamos $p_{plonky2}$ para aquellos que serán procesados por Noirky2 y $p_{barretenberg}$ para los que serán procesados por Barretenberg. 

\subsubsection{\textbf{Programas orientados a operaciones de memoria}}
El template de programa utilizado es el que se puede ver en el programa \ref{lst:familia_memoria}. 

\begin{listing}[H]
\caption{Familia de programas orientada a operaciones de memoria, variando cantidad de iteraciones}
\label{lst:familia_memoria}
\begin{minted}[frame=single, framesep=10pt, bgcolor=white]{rust}
fn main(idx: Field, val: Field) -> pub Field {
    let mut arr: [Field; 100] = [0; 100];
    for _ in 0..N {
        arr[idx] = val;
        assert(arr[idx] == val);
    }
    arr[idx]
}
\end{minted}
\end{listing}

El codigo ACIR generado se compone de $N$ bloques consecutivos como los que se pueden ver en la figura \ref{fig:ACIR_familia_memoria} (pero inicializando el bloque de memoria una única vez).

\begin{figure}[H]
    \centering
    \begin{verbatim}
    EXPR [ (-1, v) 0 ]
    INIT (id: 0, len: 100) 
    MEM (id: 0, write w at: z) 
    MEM (id: 0, read at: w, value: x)
    \end{verbatim}
    \caption{Bloque de ACIR para la familia de programas orientada a memoria}
    \label{fig:ACIR_familia_memoria}
\end{figure}

Concretamente, el programa recibe un índice $idx < N$ y un $val \in [0,p)$. Se declara una lista de tamaño $100$ llena de ceros y se realiza $N$ veces la acción de asignar el valor en la posición. Tanto el valor como la posición tienen que ser inputs para que Nargo no resuelva la operación con AssertZeros y podamos ver operaciones de memoria en el ACIR. Por otro lado, la comparación de \texttt{assert(arr[idx] == val);} es necesaria porque sino Nargo simplifica el programa y tampoco genera opcodes de memoria. 

En este caso resultó imposible aislar opcodes únicamente de memoria en el código ACIR y por lo tanto tenemos 1 AssertZero involucrado por bloque. Debido al alto costo estimado de las operaciones de memoria en relación a los AssertZero, vamos a asumir que estos últimos no van a afectar significativamente la performance ya que el cuello de botella se encuentra en las operaciones de memoria. Una forma de verificar esta hipótesis con resultados será comparar la performance de los programas orientados a AssertZero con la de los programas orientados a memoria. 

También vamos a usar una familia de programas orientada a operaciones de memoria, donde a diferencia del caso anterior vamos a variar el tamaño la lista preservando la cantidad de iteraciones. El template de Noir utilizado se puede ver en el programa \ref{lst:familia_memoria_wide}.

\begin{listing}[H]
\caption{Familia de programas orientada a operaciones de memoria, variando tamaño de la lista}
\label{lst:familia_memoria_wide}
\begin{minted}[frame=single, framesep=10pt, bgcolor=white]{rust}
fn main(idx: Field, val: Field) -> pub Field {
    let mut arr: [Field; N] = [0; N];
    for _ in 0..100 {
        arr[idx] = val;
        assert(arr[idx] == val);
    }
    arr[idx]
}
\end{minted}
\end{listing}

Es importante notar también que al medir la performance o el tamaño de los artefactos generados, no afectan ni los valores de la lista o los índices que se leen. 

\subsubsection{\textbf{Programas orientados a RangeCheck}}
El template de programa utilizado es el que se puede ver en el programa \ref{lst:familia_range_check}.

\begin{listing}[H]
\caption{Familia de programas orientada a RangeCheck}
\label{lst:familia_range_check}
\begin{minted}[frame=single, framesep=10pt, bgcolor=white]{rust}
fn main(a: [uK; N]) {}
\end{minted}
\end{listing}

En este caso la meta-variable $K$ tomará los valores de $\{8, 16, 32\}$, generando programas donde se chequea el rango de $u8$, $u16$ y $u32$ respectivamente. También se usará la meta-variable $N$ para generar programas que varíen en la cantidad de estas operaciones. Como se puede ver, el cuerpo del programa está vacío, alcanza con declarar a los inputs como $u8$, $u16$ o $u32$ para que el ACIR generado necesite chequear el rango de estas variables. 


\subsubsection{\textbf{Programas orientados a XOR}}
El template de programa utilizado es el que se puede ver en el programa \ref{lst:familia_xor}. Al igual que en el ejemplo anterior, la meta-variable $K$ sirve para identificar el tamaño en bits de los operandos y $N$ para determinar la cantidad de operaciones. 

\begin{listing}[H]
\caption{Familia de programas orientada a XOR}
\label{lst:familia_xor}
\begin{minted}[frame=single, framesep=10pt, bgcolor=white]{rust}
fn main(a: uK, b: uK) -> pub uK {
    let mut c: uK = a;
    for _ in 0..N {
        c = c ^ b;
    }
    c
}
\end{minted}
\end{listing}

En este caso, el programa va a realizar $N$ operaciones de XOR que va a acumular en una variable. La forma del programa nuevamente es arbitraria, pero sirve para que el ACIR generado tenga $N$ opcodes de tipo XOR. 

\subsection{Variantes de Noirky2}
Para el análisis (tanto de tiempos como de tamaño de artefactos) vamos a tomar 2 posibles variaciones para Noirky2:
\begin{enumerate}
    \item Propiedad de \textbf{Blinding}. Los circuitos de Plonky2 pueden ser configurados para procesarse con o sin blinding en sus polinomios. Una forma de blinding fue vista en la sección \ref{sec:blinding}, sin embargo cada implementación de un protocolo puede tener sus propias variantes. Vamos a considerar 2 opciones: \textbf{con blinding} y \textbf{sin blinding}.
    \item \textbf{Lookup Tables vs. operaciones de bits}. Para las operaciones de RangeCheck y de XOR consideramos 2 alternativas a la hora de traducirlas en las secciones \ref{sec:traduccion_range} y \ref{sec:traduccion_xor} respectivamente. Vamos a querer estudiar ambas variantes en las operaciones pertinentes. 
\end{enumerate}

Con estas opciones en mente vemos que tenemos 4 variantes de Noirky2 (con blinding y operaciones de bits, con blinding y operaciones con lookup table, sin blinding y operaciones de bits, sin blinding y operaciones con lookup table). A la hora de estudiar las familias de programa de AssertZero y operaciones de memoria solo nos van a interesar la primera y la tercera, ya que no nos interesa variar cómo se resuelven los RangeCheck ni el XOR. 

\subsection{Blowup factor}
El \textbf{blowup factor} (también conocido como ''bits de seguridad'') fue explicado en la sección \ref{sec:zippel}. Tanto Plonky2 como Barretenberg cuentan con ciertos bits de seguridad para distintas partes del protocolo, y para realizar una comparación justa es necesario que estén equiparados en este sentido. En ambos casos, los bits de seguridad se encuentran entre $100$ y $110$, con lo cual podemos decir que son comparables en la seguridad que brindan.

\subsection{Medición de tiempos}
Las mediciones de tiempos de ejecución se realizaran en una PC con las siguientes características:
\begin{itemize}
    \item OS: Ubuntu 22.04 LTS (64 bits)
    \item CPU: 11th Gen Intel® Core™ i7-1165G7 @ 2.80GHz × 8
    \item GPU: Mesa Intel® Xe Graphics (TGL GT2)
    \item RAM: 16GB
\end{itemize}

Hay 3 tiempos que nos interesa medir: la generación de la prueba, la generación de la verifying key y la verificación de la prueba. Cada una de estas operaciones se corresponde con la ejecución de los comandos \textbf{prove}, \textbf{write\_vk} y \textbf{verify} respectivamente, descritos en la sección \ref{sec:noir}. En todos los casos caso se realizarán $20$ mediciones bajo las mismas condiciones sobre un mismo experimento para normalizar el ruido del ambiente. 


Plantear hipótesis que involucren comparaciones entre Plonky2 y Barretenberg está fuera del alcance de este trabajo debido a que para hacer eso deberíamos hacer un análisis profundo de la complejidad teórica de ambas herramientas (una de las cuales no se encuentra documentada). Si bien ambas son implementaciones del protocolo Turbo-PLONK, usan dos Polynomial Commitment Schemes distintos con implementaciones propias, las cuales tampoco se encuentran documentadas. Dicho esto, es de interés hacer una comparación de performance entre ambas en forma de reporte.

Por otro lado, RangeCheck y XOR son 2 opcodes que tienen 2 posibles implementaciones en Noirky2, es decir, con o sin lookup tables. En este caso sí vamos a plantear una hipótesis concreta que queremos verificar a través de la experimentación:

\textit{Las implementaciones tanto de RangeCheck como de XOR con lookup tables tienen un costo adicional relacionado con la creación de las tablas. Para programas donde se hagan pocas operaciones de estos tipos, el tiempo dedicado a la creación de la tabla es muy grande para que valga la pena crearlas. Sin embargo, cuando un programa contiene una cantidad suficiente de estas operaciones, la suma de los costos de las operaciones bit a bit será mayor que la combinación del costo de la creación de la tabla y todas las operaciones de búsqueda en ella.}

Dicho en otras palabras, esperamos que exista un $N$ a partir del cual es conveniente usar operaciones con lookup tables. 

\subsection{Medición de tamaño de artefactos}
Los artefactos que nos interesa medir son la \textbf{Verifying Key} y la \textbf{prueba} de cada uno de los ejemplos, tanto de Barretenberg como de cada una de las variantes de Noirky2. Hay un par de hipótesis a validar en este aspecto. 
\begin{enumerate}
    \item Las pruebas de Barretenberg van a tener un menor tamaño respecto a las de Noirky2. Esto se debe a que el tamaño de la prueba depende principalmente del Ploynomial Comitment Scheme (FRI o KZG). En el caso de Barretenberg, el tamaño de la prueba debería ser constante, compuesto por algunos puntos de curva elíptica. En el caso de Plonky2, el PCS usado es FRI, que para obtener el mismo grado de seguridad que en KZG se obtiene eligiendo una curva adecuada, en FRI se consigue aumentando la cantidad de iteraciones y por ende el tamaño del transcript (ver sección \ref{sec:shamir}). 
\end{enumerate}

En este caso alcanza con realizar una única iteración por experimento, ya que el tamaño de los artefactos no depende del azar o del ambiente. 


\part{Resultados y discusión}
%La tesis está en https://github.com/eryxcoop/acvm-backend-plonky2
%Hacer un repo para la tesis, fork, meter lo de experimentación ahi, ahí después también va a estar el pdf con la tesis.
%Explicar como se conforma el repo brevemente. ¿Qué hay en el repo?


A continuación vamos a ver un reporte y análisis de los resultados obtenidos en las mediciones de tiempos de los comandos \textbf{prove}, \textbf{write\_vk} y \textbf{verify} y tamaños de los 2 artefactos generados en los comandos \textbf{prove} y \textbf{write\_vk}. Los resultados se corresponden con la experimentación planteada en la sección \ref{sec:materiales_y_metodos}. 

Las distintas cantidades de operaciones usadas para cada familia de programas pueden verse en la tabla \ref{tab:tamanio_por_programa}. Notamos que no en todos los casos la cantidad de operaciones elegida es la misma, y esto se debe a que hay operaciones que llevan más tiempo que otras. Hubo un proceso de estimación manual orientado a que la experimentación completa pueda correrse en menos de 24hs. Además, se pudo observar que hacer mediciones con una cantidad tan grande de operaciones no siempre aportaba información tan relevante.

\begin{table}[h!]
\centering
\begin{tabular}{lccccc} 

AssertZero   & 100 & 1000 & 10000 & 100000 & 1000000 \\
Memory       & 100 & 500  & 1000  & 3000  & - \\
Memory Wide  & 100 & 500  & 1000  & 3000  & - \\
Range u8     & 1000 & 2000 & 5000 & 10000 & 20000 \\
Rango u16    & 1000 & 2000 & 5000 & 10000 & 20000 \\
Rango u32    & 1000 & 2000 & 5000 & 10000 & 20000 \\
Xor u8       & 1000 & 2000 & 5000 & 10000 & 20000 \\
Xor u16      & 1000 & 2000 & 5000 & 10000 & 20000 \\
Xor u32      & 1000 & 2000 & 5000 & 10000 & 20000 \\
\hline
\end{tabular}
\caption{Tamaños elegidos para cada familia de programas}
\label{tab:tamanio_por_programa}
\end{table}


\section{Análisis de tiempos}

Vamos a hacer algunas observaciones a grandes rasgos de cada uno de los comandos (prove, write\_vk y verify) para luego pasar a un estudio más enfocado en cada operación individual, en los casos donde esto tenga sentido. En este análisis tenemos que tener en cuenta, como se dijo en la sección \ref{sec:noir}, que el comando \texttt{write\_vk} realiza un subconjunto de las acciones del comando \texttt{prove}. Por esto mismo esperamos ver que los tiempos de ejecución del segundo sean estrictamente superiores que los del primero. Por esta razón también nos vamos a enfocar más en los tiempos de generación de la prueba, ya que representa el flujo más completo del sistema. Los gráficos completos pueden encontrarse en el apéndice \ref{sec:apendice_graficos}. En esta sección solo vamos a mostrar aquellos que sean de interés para conclusiones determinadas. 

\subsubsection{Comando \textbf{prove}}

Comencemos viendo los resultados del comando \textbf{prove} en la figura \ref{fig:prove_tiempos}. Hay una generalidad que podemos observar en todos los casos. A grandes rasgos tenemos 2 variantes de Noirky2 para implementar las operaciones de Range y de XOR. Estas son bit a bit o usando lookup tables. Para cada una de estas también tenemos la opción de aplicar un blinding sobre la traza o no hacerlo. Podemos ver que en todos los casos, aplicar ese blinding incurre en un costo adicional, es decir, la versión que aplica este blinding siempre tiene un tiempo de ejecución mayor a la que no. Esto tiene sentido, ya que la fase de procesamiento de la traza en la generación de la prueba va a tener un costo mayor porque tienen que interpolarse polinomios de grado mayor. Podemos ver un representante de este fenómeno en la figura \ref{fig:prove_tiempo_representante}, con el caso del comando \textbf{XOR u8}.

\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/prove-Xor-u8.png}
	\caption{Representante de los tiempos de ejecución del comando \textbf{Prove}}
	\label{fig:prove_tiempo_representante}
\end{figure}

\subsubsection{Comando \textbf{write\_vk}}

A continuación, veamos el caso de la operación \textbf{write\_vk}. Los resultados pueden verse en la figura \ref{fig:write_vk_tiempos}. Retomamos en este caso la observación realizada en el comando prove y vemos que esta se mantiene, aunque de forma menos notable. Un representante de este fenómeno puede encontrarse en la figura \ref{fig:write_vk_tiempo_representante}.

\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/write_vk-Xor-u8.png}
	\caption{Representante de los tiempos de ejecución del comando \textbf{write\_vk}}
	\label{fig:write_vk_tiempo_representante}
\end{figure}

\subsubsection{\textbf{prove} vs. \textbf{write\_vk}}

En este punto vamos a hacer una comparación entre los tiempos de ejecución del comando \textbf{prove} y el comando \textbf{write\_vk} para el caso de Noirky2 con blinding para el opcode \texttt{AssertZero}. Como podemos ver en la figura \ref{fig:prove_vs_write_vk}, los tiempos de ejecución del comando \textbf{prove} son mayores, y esto es esperable dado que \textbf{write\_vk} realiza un subconjunto de las acciones que realiza \textbf{prove}, como ya habíamos adelantado. Esto se va a repetir en todos los opcodes, en todas las variantes de Noirky2.


\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/prove-vs-vk-AssertZero-Noirky2.png}
	\caption{Representante de los tiempos de ejecución del comando \textbf{prove} vs. el comando \textbf{write\_vk}}
	\label{fig:prove_vs_write_vk}
\end{figure}

\subsubsection{Comando \textbf{verify}}

Finalmente, vamos a ver los tiempos de la operación \textbf{verify}. Los resultados pueden verse en la figura \ref{fig:verify_tiempos}. Si bien en esta operación estamos viendo órdenes de magnitud mucho menores (del orden de $5ms$ a $25ms$ contra $1s$ a $50s$ en las operaciones de \texttt{prove} y \texttt{write\_vk}), podemos notar  en todos los casos que:
\begin{itemize}
    \item Los tiempos de ejecución parecen estabilizarse en un tiempo constante, o por lo menos de crecimiento muy leve frente al aumento de cantidad de operaciones. Esto se ve especialmente en el caso del AssertZero, donde incluso ejecutando $1.000.000$ de operaciones se observa un crecimiento muy leve en los tiempos de ejecución.
    \item Barretenberg (con KZG) tarda siempre un tiempo cercano a los $25ms$ mientras que todas las versiones de Noirky2 (con FRI) tardan alrededor de $5ms$. Esta comparación está más relacionada con la implementación de los provers en sí que con la implementación realizada en este trabajo. 
\end{itemize}

Para dejar constancia de este comportamiento vamos a tomar como representante el caso del AssertZero, como podemos ver en la figura \ref{fig:verify_tiempo_representante}, pero teniendo en mente que todas las familias de programas se comportan de manera similar. 

\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/verify-Assert Zero.png}
	\caption{Representante de los tiempos de ejecución del comando \textbf{Verify}}
	\label{fig:verify_tiempo_representante}
\end{figure}



Estos provers (Barretenberg y Plonky2) están diseñados para depositar el costo de la ejecución en la generación de la prueba, permitiendo que la verificación sea rápida o \texttt{succint} (recordemos que ese es uno de los principios básicos de los SNARKs descritos en la sección \ref{sec:snarks}). Este es un resultado esperable, y no vamos a prestar más atención a los tiempos de ejecución del comando \textbf{verify} en el análisis que viene. 



\subsection{Análisis particular de opcodes}
A continuación vamos a hacer un un foco en los opcodes. En este caso también vamos a querer comparar las implementaciones entre si. Vamos a centrarnos en particular en el comando \texttt{prove} porque consideramos que es el más representativo, ya que ejecuta el flujo completo que incluye la traducción de Noir a Plonky2, la generación de la verifying key y la generación de la prueba. Vamos a dejar a la verificación de lado ya que como vimos, su análisis no presenta tanto interés. 

\subsubsection{AssertZero}
Comencemos por el AssertZero. En este caso vamos a ver los tiempos de ejecución con muchas y con pocas operaciones, ya que puede llegar a ser de interés ver cómo se comporta esta herramienta para programas de Noir relativamente pequeños. Para ver el comportamiento con muchas operaciones (específicamente, $1000000$) nos remitimos a la figura \ref{fig:muchas_operaciones}. Podemos ver que a medida que la cantidad de operaciones crece, el tiempo de ejecución aparenta tener un crecimiento lineal, teniendo el backend de Barretenberg una pendiente más pronunciada que aquellas variantes de Noirky2. En particular, para $1000000$ de operaciones, la ejecución de este comando tarda $20$ segundos más con Barretenberg que con Noirky2, representando aproximadamente un $50\%$ más de tiempo de ejecución. 

Para ver el comportamiento en casos más pequeños, veamos el gráfico de la figura  \ref{fig:pocas_operaciones}. En este caso, la escala del eje horizontal es logarítmica para facilitar la vista. Lo que es interesante de este gráfico es que existe una cantidad de operaciones $k$ tal que si queremos generar una prueba de menos de $k \approx 20000$ opcodes de tipo AssertZero, opera más rápido el backend de Barretenberg. Sin embargo para valores mayores a $k$ ya es conveniente usar Noirky2, en lo que respecta a tiempo de ejecución de la prueba. Por completitud aclaramos que si no fuera de interés aplicar un blinding sobre los datos, siempre es conveniente usar Noirky2 sin blinding, pero compararlos de forma directa no sería del todo justo ya que esta variante no posee el mismo grado de seguridad que las otras dos. 


\begin{figure}
	\centering
	\begin{subfigure}[t]{0.49\textwidth} 
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Assert Zero-log.png}
		\caption{Hasta $100.000$ operaciones, vista logarítmica}
		\label{fig:pocas_operaciones}
	\end{subfigure}%
	\hfill 
	\begin{subfigure}[t]{0.49\textwidth}  
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Assert Zero.png}
		\caption{Hasta $1.000.000$ de operaciones}
		\label{fig:muchas_operaciones}
	\end{subfigure}
	\caption{Comando \textbf{prove} del opcode AssertZero, tiempos de ejecución para pocas y muchas operaciones}
	\label{fig:assert_zero_pocas_y_muchas}
\end{figure}



\subsubsection{Operaciones de memoria}
Avancemos entonces a las operaciones de memoria. Recordemos que tenemos 2 variantes en los programas: uno que aumenta la cantidad de lecturas y escrituras en una lista de tamaño 100; y otra que aumenta el tamaño de la lista pero siempre realiza 100 lecturas y escrituras. 

Antes de comenzar vamos a validar una pequeña hipótesis que planteamos en la sección \ref{sec:materiales_y_metodos}: una operación de AssertZero es despreciable en cuanto a tiempo de procesamiento en comparación con una operación de memoria. Tuvimos que plantear esta hipótesis porque no fue posible armar un programa que tuviera operaciones de memoria aisladas del AssertZero. Para validarla, vamos a tomar 2 Backends: Barretenberg y Noirky2 con blinding, y comparar directamente los tiempos de ejecución de las operaciones de memoria con los de AssertZero. La comparación puede verse en la figura \ref{fig:mem_vs_assert_zero}. 

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{imagenes/tiempos/prove-AssertZero-vs-mem-Noirky2.png}
        \caption{Memoria vs. Assert Zero, Noirky2 con blinding}
        \label{fig:mem_vs_assert_zero_noirky}
    \end{subfigure}%
    \hfill 
    \begin{subfigure}[t]{0.45\textwidth}  
        \centering
        \includegraphics[width=\textwidth]{imagenes/tiempos/prove-AssertZero-vs-mem-Barretenberg.png}
        \caption{Memoria vs. Assert Zero, Barretenberg}
        \label{fig:mem_vs_assert_zero_barretenberg}
    \end{subfigure}
    \caption{Comparación de opcodes de memoria vs opcodes de AssertZero}
    \label{fig:mem_vs_assert_zero}
\end{figure}

Notamos que en el caso de Noirky2 esta diferencia es notable: el crecimiento de los tiempos de ejecución es marcadamente diferente (como se ve en la figura \ref{fig:mem_vs_assert_zero_noirky}). Sin embargo, cuando usamos Barretenberg esta diferencia no es tan marcada (como se ve en la figura \ref{fig:mem_vs_assert_zero_barretenberg}). A su vez, si prestamos atención a la escala de ambos gráficos, vemos que los tiempos de ejecución con Noirky2 para las operaciones de memoria son mucho mayores que los de Barretenberg. Para ver mejor este fenómeno podemos tomar como ejemplo el gráfico de \ref{fig:tiempo-prove-mem-rep}, donde se muestra que cuando aumenta la cantidad de operaciones de memoria el backend de Barretenberg actúa de forma mucho más veloz.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/prove-Memoria (varía operaciones).png}
	\caption{Memoria (operaciones)}
	\label{fig:tiempo-prove-mem-rep}
\end{figure}%

La diferencia en los tiempos de ejecución de ambos backends (Noirky2 y Barretenberg) es tan marcada que nos hace pensar que las implementaciones de lectura y escritura hechas por Barretenberg se basan en restricciones polinomiales distintas a las de Noirky2. Esto puede dar lugar a una investigación más profunda sobre Barretenberg para ver cómo esta herramienta simula con restricciones polinomiales la lectura y escritura en un bloque de memoria. 


\subsubsection{Operaciones de Range}\label{sec:tiempo_range}
Finalmente llegamos a familias de programas donde tenemos variantes implementativas entre los backends de Noirky2. Con esto me refiero que tenemos por un lado implementaciones basadas en Lookup Tables y por otro lado implementaciones basadas en operaciones de bits. Vamos a dejar de lado para este análisis las implementaciones de Noirky2 sin blinding. 

Si comparamos únicamente las implementaciones de Noirky2 con Lookup Tables y con Bits, podemos ver que parece cumplirse una de las hipótesis planteadas anteriormente: las Lookup Tables tienen mejor performance cuando crece la cantidad de operaciones pero a un costo de inicialización muy alto. Un ejemplo de esto lo podemos ver en la figura \ref{fig:range_table_vs_bit}, que muestra el ejemplo de los opcodes de tipo \textbf{Range-u8}, para el comando \textbf{prove}.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/prove-Range-u8-table-vs-bits.png}
	\caption{Prove - Range-u8 - Noirky2: Lookup Tables vs. operaciones bit a bit}
	\label{fig:range_table_vs_bit}
\end{figure}%

Por otro lado, nos interesa comparar la performance de Barretenberg con la de Noirky2. Los gráficos completos pueden verse en las figuras \ref{fig:tiempo-prove-range-u8}, \ref{fig:tiempo-prove-range-u16} y \ref{fig:tiempo-prove-range-u32}. Estos resultados tienen sin embargo una particularidad que resulta anti-intuitiva para explicar: tanto la implementación de Noirky2 con operaciones de bits como Barretenberg presentan saltos discretos en sus tiempos de ejecución. Estas mediciones fueron repetidas en varias ocasiones para descartar un posible problema de ambiente. Estos saltos dificultan la comparación, y se necesitaría un análisis más exhaustivo de las implementaciones de las Custom Gates de Barretenberg y Plonky2 para explicarlos. Un representante de este comportamiento se puede ver en el gráfico \ref{fig:range_noirky_vs_barretenberg}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{imagenes/tiempos/prove-Range-u16-Noirky2-vs-Barretenberg.png}
	\caption{Prove - Range-u16 - Noirky2 vs. Barretenberg}
	\label{fig:range_noirky_vs_barretenberg}
\end{figure}%

\subsubsection{Operaciones de XOR}\label{sec:tiempo_xor}
En el caso del XOR, tenemos nuevamente una implementación de Noirky2 basada en Lookup Tables y una basada en operaciones de bits, además de Barretenberg. Al igual que en el caso anterior, vamos a ignorar las variantes de Noirky2 sin blinding ya que se comportan de modo muy similar a sus correspondientes variantes con blinding, en lo que respecta a tiempos de ejecución.

Los gráficos para realizar este análisis fueron presentados en las figuras \ref{fig:tiempo-prove-xor-u8} (XOR u8), \ref{fig:tiempo-prove-xor-u16} (XOR u16) y \ref{fig:tiempo-prove-xor-u32} (XOR u32). En ellos podemos ver claramente que todos se comportan de forma lineal, pero Barretenberg tiene la pendiente más pronunciada y por ende peores tiempos de ejecución. Por otro lado, comparando ambas implementaciones de Noirky2, notamos que la que usa Lookup Tables tiene una pendiente mucho más llana que aquella con operaciones de bits. En el caso de XOR u8 incluso parecería no haber variaciones entre la ejecución de $1000$ y $20.000$ operaciones, siendo el grueso del cómputo el overhead de la creación de las Lookup Tables. A su vez, notamos un crecimiento lineal en la cantidad de operaciones en el caso de Noirky2 con operaciones bit-a-bit. Un ejemplo de esto podemos verlo concretamente en el caso del opcode \textbf{XOR-u16} en la figura \ref{fig:tiempo-prove-xor-u16-representante}.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth]{imagenes/tiempos/prove-Xor-u16-Noirky2-vs-Barretenberg.png}
	\caption{Prove - XOR u16}
	\label{fig:tiempo-prove-xor-u16-representante}
\end{figure}%


Por otro lado, notamos que en las variantes con Noirky2, pasar de XOR u8 a XOR u16 y XOR u32 presenta pendientes cada vez más pronunciadas, mientras que Barretenberg tiene los mismos tiempos de ejecución para todas las operaciones de XOR, dada una cantidad de operaciones. Esto se ve especialmente en el caso Noirky2 con operaciones de bits, como podemos apreciar en la figura \ref{fig:prove-Xor-Noirky2-bits}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth]{imagenes/tiempos/prove-Xor-Noirky2-bits.png}
	\caption{Prove - XOR u8/u16/u32 - Noirky2 con operaciones de bits}
	\label{fig:prove-Xor-Noirky2-bits}
\end{figure}%



\section{Análisis de tamaños de artefactos}
En esta sección vamos a hacer un reporte de los tamaños de los artefactos generados en el flujo de trabajo. Estos artefactos son la \textbf{Verification Key} en el caso del comando \textbf{write\_vk} y la \textbf{prueba} en el caso del comando \textbf{prove}.

\subsection{Tamaño de la Verification Key}
Comencemos por ver los tamaños que tiene cada verification key, segun la cantidad de opcodes de cada tipo. Los resultados completos pueden verse en la figura \ref{fig:tamanios-vk}. Algo que notamos en todos los gráficos es que tanto Barretenberg como Noirky2 con operaciones de bits tienen el mismo tamaño de Verification Key para todas las familias de programas (por una cuestión de escala, esto no se percibe en el gráfico de las operaciones de XOR, pero fue constatado con los datos). Además, aplicar blindings no afecta en ningún caso el tamaño de la Verification Key. Un representante de este fenómeno lo encontramos en el caso del AssertZero como se ve en la figura \ref{fig:tamanio-vk-assert-zero-ej}, sin embargo esto es así en todos los casos.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth]{imagenes/tamanios/tamanio-write_vk-Assert Zero.png}
	\caption{Tamaño de la VK en Noirky2 con operaciones de bits y Barretenberg}
	\label{fig:tamanio-vk-assert-zero-ej}
\end{figure}%

Las diferencias pueden empezar a verse cuando usamos Lookup Tables. Recordemos que estas permiten tener tablas pre-computadas en la Verification Key, permitiendo tiempos de ejecución mucho más rápidos como vimos en las secciones \ref{sec:tiempo_range} y \ref{sec:tiempo_xor}. Sin embargo, acá podemos ver cómo esto trae desventajas en los tamaños de la verification key. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth]{imagenes/tamanios/tamanio-write_vk-Xor-u8.png}
	\caption{Tamaño de la VK para operaciones de tipo Xor}
	\label{fig:tamanio-vk-xor-u8-ej}
\end{figure}%

En el caso de las operaciones de Range con Lookup Tables, estas usan una tabla simple de $2^8$ elementos de cuerpo, y eso se ve reflejado en el aumento visible en las figuras \ref{fig:tamanio-vk-range-u8}, \ref{fig:tamanio-vk-range-u16} y \ref{fig:tamanio-vk-range-u32}, que es igual en todos los casos. Por otro lado, cuando nos movemos al caso del XOR, estamos usando tablas de $2^{16}$ elementos, por lo cual el grueso de la Verification Key se ve ocupado por esta tabla. Esto hace que se opaque casi en su totalidad a las otras implementaciones, como podemos ver en la figura \ref{fig:tamanio-vk-xor-u8-ej}, superando el tamaño de 250kb. 

\subsection{Tamaño de la prueba}
Nos movemos ahora al tamaño de las pruebas generadas. Los resultados completos pueden verse en la figura \ref{fig:tamanios-prueba}. En este caso, podemos ver que Barretenberg presenta una clara ventaja frente a Plonky2: los tamaños de sus pruebas son constantes. En todos los casos, la prueba pesa $2176$ bytes o $2.125$ kb. Esto se debe a que el Polynomial Commitment Scheme usado es KZG, explorado en la sección \ref{sec:kzg}. Esto no es así en el caso de Plonky2, que usa FRI. 

Notamos que en todas las variantes de Noirky2 la prueba es igual o más grande cuando se aplica un blinding, comparado con su respectiva variante. También notamos que esta diferencia tiende a igualarse a medida que aumenta la cantidad de operaciones. Estos fenómenos así como lo mencionado en el párrafo anterior puede verse representado en la figura \ref{fig:tamanio-prueba-range-u8-ejemplo}, donde tomamos como ejemplo el caso del opcode \textbf{Range-u8}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.6\textwidth]{imagenes/tamanios/tamanio-prove-Range-u8.png}
\caption{Tamaño de prueba - Range-u8 - Todos los backends}
\label{fig:tamanio-prueba-range-u8-ejemplo}
\end{figure}%

\subsection{Comparación entre artefactos y el CRS}
Para finalizar el análisis quiero hacer una comparación entre los tamaños de las pruebas generadas y el tamaño del CRS de KZG visto en la sección \ref{sec:costo_crs}. La idea de este trabajo fue librarnos de tener que usar una herramienta que requiriera un CRS potencialmente muy pesado para generar pruebas. Es interesante ver en este contexto si esto efectivamente aporta algún valor. Por ejemplo, si el tamaño de las pruebas fuera mucho mayor a las del CRS necesario para un programa con un tamaño dado, usar FRI en lugar de KZG no presentaría una ventaja tan grande ya que el cuello de botella no estaría en el CRS requerido por KZG. 

Para hacer este análisis vamos a comparar el tamaño del CRS necesario para procesar una traza de largo $N$ con el tamaño de los artefactos generados para esa misma traza (Prueba y Verification Key). Vamos a usar únicamente la familia de programas orientados a AssertZero para acotar este análisis. Recordemos de la sección \ref{sec:plonky2} que el ancho de la traza es de 135 columnas y que Plonky2 empaqueta restricciones polinomiales del mismo tipo en una misma fila de la traza. Esto sumado a que una operación de AssertZero como las que usamos en el ejemplo ocupa 9 casillas de la traza (ya que son 3 términos matemáticos donde cada uno ocupa 3 casillas en la traza) nos permite saber un largo aproximado de la traza para una cantidad de operaciones dada. El resultado es 
$$\frac{9\cdot N}{135} = \frac{N}{15} $$

Entonces por ejemplo, si realizamos 10000 operaciones de tipo AssertZero, Noirky2 va a generar una traza de Plonky2 con un estimado de $10000/15 \approx 666$ filas. Volviéndonos a la tabla \ref{tab:costo_crs} el CRS tendría que tener un tamaño mínimo de $62kb$. Para esta cantidad de operaciones, la figura \ref{fig:tamanio-prueba-assert-zero} nos muestra que una prueba de Plonky2 para este programa pesa aproximadamente $125kb$, que es un tamaño mayor al del CRS. Sin embargo, si tomamos un programa con $1000000$ de AssertZeros, la traza de Plonky2 tendría un largo de aproximadamente $66666$ y por ende el CRS tendría un tamaño mínimo de $6200kb$, superando ampliamente a los aproximadamente $150kb$ de la prueba para este mismo tamaño.

¿Qué nos dice esto? Para programas chicos, en términos espaciales, usar Noirky2 en lugar de Barretenberg no presenta ventajas. Sin embargo, cuando los programas crecen, el crecimiento del CRS en función de la cantidad de operaciones es mucho más pronunciado que el del tamaño de las pruebas. Resultados más detallados pueden verse en la tabla \ref{tab:CRS_vs_prueba}.


\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{N} & 100 & 1000 & 10000 & 10000 & 100000\\ \hline
\textbf{Prueba} & 118kb& 115kb& 120kb& 126kb& 145kb\\ \hline
\textbf{CRS} & 0.6kb& 6.2kb& 62kb& 620kb& 6201kb \\ \hline
\end{tabular}
\caption{Comparación entre el tamaño del CRS y el tamaño de la prueba}
\label{tab:CRS_vs_prueba}
\end{table}

\part{Conclusiones y trabajo futuro}

\subsubsection{Conclusiones}

Este trabajo trajo consigo muchos desafíos, tanto teóricos como de implementación, y es momento de hacer un pequeño resumen de las cosas aprendidas. 

Respecto a la implementación en sí, se construyó una herramienta (Noirky2) que depende de otras dos (Plonky2 y Noir), lo cual fue especialmente complicado teniendo en cuenta que el repositorio de Noir estaba en una versión inestable y recibía muchos cambios todos los días (todavía lo hace). En cierto punto se decidió fijar una versión, pero para usar Noirky2 de forma productiva habría que actualizar la herramienta para que se adapte a la versión más nueva de Noir.

Respecto al uso de la herramienta en sí, pudimos ver que no hay una receta perfecta para la generación de pruebas de programas en Noir. El backend que tengamos que usar y su respectiva variante va a depender del tamaño del programa y del tipo de operaciones que predominen en él. Por ejemplo, para algunos programas muy chicos vimos que conviene usar Barretenberg, tanto temporal como espacialmente. Sin embargo, para programas más grandes, a menos que sea un programa con muchas operaciones de memoria, conviene usar Noirky2. El uso de Lookup Tables frente a operaciones de bits debe estar pautado por la cantidad de operaciones de tipo XOR o Range que haya en el programa, ya que el costo de inicializar esa tabla es muy alto. Por otro lado, si no es crítica la propiedad de \textbf{ZK} en la prueba, siempre conviene NO aplicar un blinding en Noirky2 en términos del tiempo de generación de la prueba.

Por último, también vimos que el costo del CRS crece de manera mucho más acelerada que las pruebas de Plonky2. Esto hace que para programas relativamente chicos tenga sentido usar Barretenberg, ya que el CRS tendrá un tamaño pequeño. Sin embargo para programas que pasen cierto tamaño, el CRS se transforma en un cuello de botella para la memoria del dispositivo que genera las pruebas, y por ende puede ser limitante para ellos. 

\subsubsection{Trabajo futuro}

Me gustaría finalizar dejando en claro las cosas que no se llegaron a estudiar y posibles continuaciones de este trabajo. 

\begin{itemize}
	\item Hacer tests por la negativa para verificar que las restricciones están presentes. Esto fue desarrollado en la sección \ref{sec:tests}.
	\item Analizar en detalle el código de Barretenberg para explicar por qué son tanto más rápidas las operaciones de memoria. 
	\item Analizar las implementaciones de las Custom Gates de Plonky2 y Barretenberg para explicar los saltos discretos que se dan en las mediciones de tiempos del opcode \textbf{Range}.
	\item Hacer un análisis más profundo de cómo crecen los tamaños de las pruebas en los casos donde esto tenga sentido.
	\item Explorar en más detalle la forma en la que cada opcode ocupa la traza de Plonky2 para hacer un modelo teórico de la traza en sí misma que permita explicar mejor los tiempos de ejecución. 
	\item Se podrían crear Custom Gates de Plonky2 para operaciones como las de memoria, o AssertZero, pensando en llenar la traza de la forma más eficiente posible. 
	\item Hoy en día existen más backends de Noir hechos con otros provers. Estos backends no existían al momento de comenzar este trabajo. Se podría hacer un estudio de performance sobre los mismos, analizando ventajas y desventajas. 
	\item Se podrían aplicar modificaciones sobre Noir para que Noirky2 soporte el uso de enteros mayores a u32. Esto requeriría modificar la generación de restricciones por parte de Noir porque los enteros u64 tendrían que resolverse divididos en 2 partes (32 bits más significativos y 32 bits menos significativos).
	
	
\end{itemize}





\appendix
\chapter{Flujo completo de Noir}\label{sec:apendice_noir}
\begin{enumerate}
	\item Lo primero que tenemos que hacer instalar Nargo, el compilador de Noir.
	\item Después tenemos que crear un nuevo proyecto con el comando \texttt{nargo new nombre\_proyecto}. Esto nos generará un directorio con la siguiente estructura:
\end{enumerate}
\dirtree{%
	.1 nombre\_proyecto.
	.2 src.
	.3 main.nr.
	.2 Nargo.toml.
}
\begin{enumerate}[start=3]
	\item A continuación tenemos que escribir un programa en Noir  en el archivo \texttt{main.nr}. Noir es un lenguaje estáticamente tipado (es decir, se tiene que conocer el tipo de las variables en tiempo de compilación). Ahora es el momento donde cabe preguntarnos ¿qué tipo de programas queremos escribir en Noir? Estamos hablando de un lenguaje de propósito general, pero lo que este lenguaje nos permite es ejecutar un programa con inputs tanto públicos como privados.
	\begin{itemize}
		\item Los inputs públicos son conocidos tanto por el prover como por el verifier, potencialmente en un ejemplo del mundo real es el verifier el que provee estos inputs para delegar la ejecución del programa.
		\item Los inputs privados que solo van a ser conocidos por el prover (quien genera la prueba de ejecución).
	\end{itemize}
	Veamos un ejemplo trivial con inputs tanto públicos como privados:
	\begin{verbatim}
		fn main(x: pub Field, y: Field) {
			assert(x == y*y);
		}
	\end{verbatim}
	¿Qué es lo que hace este programa? \texttt{main} es el punto de entrada, recibe un parametro público y uno privado y no tiene un valor de retorno. Su propósito en lenguaje coloquial es generar una prueba de ejecución de que quien lo ejecuta conoce el valor de $\sqrt{x}$ en $\Fp$. 
	
	\item Lo siguiente que tenemos que hacer para generar la prueba de ejecución es proveer un listado de parámetros ''testigo'' para que este programa se instancie con valores concretos. Para esto vamos a ejecutar \texttt{nargo check}, comando que creará un archivo Prover.toml. En este archivo tenemos que completar los valores de los parámetros testigo: \texttt{x = 4 y = 2}
	
	
	
	
	\item Una vez provistos estos parámetros, lo que vamos a querer es ejecutar el programa para generar un sistema de restricciones que lo respresente. Esto concretamente toma la forma de un \textbf{ACIR} (\textit{Abstract Circuit Intermediate Representation}). Para ejecutarlo tenemos que correr el comando \texttt{nargo execute witness --print-acir}. El sistema de ecuaciones generado puede verse en la figura \ref{fig:ACIR_ejemplo_1}.
	
	\begin{figure} 
		\centering
		\begin{minipage}{0.7\textwidth}
			\begin{verbatim}
				private parameters indices : [0]
				public parameters indices : [1]
				return value indices : []
				EXPR [ (-1, _1, _1) (1, _0) 0 ]
			\end{verbatim}
		\end{minipage}
		
		\caption{ACIR para el programa de ejemplo con un AssertZero}
		\label{fig:ACIR_ejemplo_1}
	\end{figure}
	
	Vamos a desglosar lo anterior: el output de la ejecución del programa en formato ACIR se maneja con variables llamadas \textbf{Witnesses}. Los Witnesses son nombrados de forma secuencial (de 0 en adelante) según su orden de aparición en el código. 
	\begin{itemize}
		\item \textbf{private parameters indices} es un listado de los inputs privados del circuito. En nuestro programa de alto nivel llamamos \texttt{x} al input privado, pero en el ACIR este input es representado por el witness $0$. Esto se debe a que \texttt{x} es la primera variable que procesa el compilador.  
		\item \textbf{public parameters indices} es un listado de los inputs públicos del circuito. En este caso, ''y'' es representado por el witness $1$. 
		\item \textbf{return value indices} es el listado de los witness de retorno. En este caso no hay ninguno, pero serían los siguientes en ser nombrados.
		\item \textbf{Circuito}: la última linea representa la única ecuación del sistema de ecuaciones del circuito. El Opcode que denota es el \textbf{AssertZero}, con lo cual esa linea se puede traducir a la ecuación:
		
		\begin{center}
			$-1 \cdot w_1 \cdot w_1 + 1 \cdot w_0 + 0 = 0$, 
		\end{center}
		que si la despejamos es equivalente a 
		\begin{center}
			$w_0 = w_1^2$,
		\end{center}
		que es lo que el programa busca demostrar. Estamos usando la notación $w_i$ para denotar al $i$-esimo witness (lo que vimos como $\_i$). Vamos a desarrollar sobre el \texttt{AssertZero} en breve, pero antes sigamos con el flujo de generar una prueba de ejecución. 
	\end{itemize}
	En este punto el directorio debería verse parecido a esto:
	
\end{enumerate}

\noindent\parbox{\linewidth}{%
	\dirtree{%
		.1 nombre\_proyecto.
		.2 Nargo.toml.
		.2 Prover.toml.
		.2 src.
		.3 main.nr.
		.2 target.
		.3 witness.gz.
		.3 nombre\_proyecto.json.
}}

Los 2 recursos que generó la ejecución anterior son:
\begin{itemize}
	\item \textbf{ACIR}: en archivo ubicado en \texttt{target/nombre\_proyecto.json}.
	\item \textbf{Valores generados de witness}: en \texttt{target/witness.gz}. En esta instancia Nargo ya resolvió todos los valores de los witnesses. Para hacerlo, tomó $\Fp$ con 
	$$p=2^{254}+2^{224}+2^{192}+2^{96}-1$$
\end{itemize}
\begin{enumerate}[start=6]
	\item El siguiente paso va a ser generar la prueba de ejecución de este circuito. Para esto vamos a usar un prover. El único prover que sabe interpretar código ACIR al momento es \textbf{Barretenberg}, por lo cual tendremos que instalarlo. Lo siguiente que tenemos que hacer es generar la prueba de ejecución de Barretenberg, con el comando:
	
	\vspace{0.5em}
	
	\texttt{bb prove -c target/nombre\_proyecto.json -w /target/witness -o proof}
	
	\vspace{0.5em}
	
	Esto va a crear una prueba ($\pi$) de Barretenberg y la va a guardar en el archivo \texttt{nombre\_proyecto/proof}.
	
	\item A continuación queremos verificar la prueba. Esto consta de 2 partes: generar la clave de verificación y verificarla. En un caso real querríamos que la verificación sea hecha por un agente distinto al que generó la prueba, por ende, tanto la clave de verificación como la prueba deberían ser pasadas al verifier. La clave de verificación también puede ser creada por el mismo verifier. 
	
	\vspace{0.5em}
	\texttt{1. bb write\_vk -b target/nombre\_proyecto.json -o target/vk}
	
	\texttt{2. bb verify -k target/vk -p proof}
	\vspace{0.5em}
	
	El primer comando va a generar una \textbf{Verification Key} en la ruta indicada. Esta contiene toda la información necesaria para verificar la prueba: el programa codificado, los public inputs, etc. En lenguaje de PLONK, podríamos pensarlo como las matrices $Q$, $V$ y $PI$ (o sus polinomios interpoladores en un dominio $D$). El segundo comando va a realizar la verificación, valiéndose de la Verification Key y la prueba. 
	
	Es importante notar también que la semántica que da Noir a las operaciones hace que el comando \texttt{prove} y el comando \texttt{write\_vk} repitan acciones. En particular, podemos decir que \texttt{write\_vk} realiza un subconjunto de las acciones que realiza \texttt{prove} ya que este último tiene que generar una verifying key antes de poder generar la prueba. Una decisión de diseño distinta sería que el comando \texttt{prove} reciba como parámetro una proving key previamente generada, sin embargo no pretendemos en este trabajo modificar la semántica de las operaciones del programa sobre el cual deseamos construir. 
	
\end{enumerate}


\chapter{Gráficos de resultados de la experimentación}\label{sec:apendice_graficos}
\begin{figure}[htbp!]
	\centering
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Assert Zero.png}
		\caption{AssertZero}
		\label{fig:tiempo-prove-assert-zero}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Memoria (varía operaciones).png}
		\caption{Memoria (operaciones)}
		\label{fig:tiempo-prove-mem}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Memoria (varía tamaño de lista).png}
		\caption{Memoria (tamaño)}
		\label{fig:tiempo-prove-mem-wide}
	\end{minipage}
	
	\vspace{0.5cm} 
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Range-u8.png}
		\caption{Range u8}
		\label{fig:tiempo-prove-range-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Range-u16.png}
		\caption{Range u16}
		\label{fig:tiempo-prove-range-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Range-u32.png}
		\caption{Range u32}
		\label{fig:tiempo-prove-range-u32}
	\end{minipage}
	
	\vspace{0.5cm}  % Espacio entre las filas de subgráficos
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Xor-u8.png}
		\caption{XOR u8}
		\label{fig:tiempo-prove-xor-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Xor-u16.png}
		\caption{XOR u16}
		\label{fig:tiempo-prove-xor-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/prove-Xor-u32.png}
		\caption{XOR u32}
		\label{fig:tiempo-prove-xor-u32}
	\end{minipage}
	
	\caption{Mediciones de tiempos para el comando \textbf{prove} para todas las familias de programas de Noir}
	\label{fig:prove_tiempos}
\end{figure}



\begin{figure}[htbp!]
	\centering
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Assert Zero.png}
		\caption{AssertZero}
		\label{fig:tiempo-write_vk-assert-zero}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Memoria (varía operaciones).png}
		\caption{Memoria (op)}
		\label{fig:tiempo-write_vk-mem}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Memoria (varía tamaño de lista).png}
		\caption{Memoria (tamaño)}
		\label{fig:tiempo-write_vk-mem-wide}
	\end{minipage}
	
	\vspace{0.5cm} 
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Range-u8.png}
		\caption{Range u8}
		\label{fig:tiempo-write_vk-range-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Range-u16.png}
		\caption{Range u16}
		\label{fig:tiempo-write_vk-range-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Range-u32.png}
		\caption{Range u32}
		\label{fig:tiempo-write_vk-range-u32}
	\end{minipage}
	
	\vspace{0.5cm}  % Espacio entre las filas de subgráficos
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Xor-u8.png}
		\caption{XOR u8}
		\label{fig:tiempo-write_vk-xor-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Xor-u16.png}
		\caption{XOR u16}
		\label{fig:tiempo-write_vk-xor-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/write_vk-Xor-u32.png}
		\caption{XOR u32}
		\label{fig:tiempo-write_vk-xor-u32}
	\end{minipage}
	
	\caption{Mediciones de tiempos para el comando \textbf{write\_vk} para todas las familias de programas de Noir}
	\label{fig:write_vk_tiempos}
\end{figure}

\begin{figure}[htbp!]
	\centering
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Assert Zero.png}
		\caption{AssertZero}
		\label{fig:tiempo-verify-assert-zero}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Memoria (varia operaciones).png}
		\caption{Memoria (op)}
		\label{fig:tiempo-verify-mem}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Memoria (varía tamaño de lista).png}
		\caption{Memoria (tamaño)}
		\label{fig:tiempo-verify-mem-wide}
	\end{minipage}
	
	\vspace{0.5cm} 
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Range-u8.png}
		\caption{Range u8}
		\label{fig:tiempo-verify-range-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Range-u16.png}
		\caption{Range u16}
		\label{fig:tiempo-verify-range-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Range-u32.png}
		\caption{Range u32}
		\label{fig:tiempo-verify-range-u32}
	\end{minipage}
	
	\vspace{0.5cm}  % Espacio entre las filas de subgráficos
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Xor-u8.png}
		\caption{XOR u8}
		\label{fig:tiempo-verify-xor-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Xor-u16.png}
		\caption{XOR u16}
		\label{fig:tiempo-verify-xor-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tiempos/verify-Xor-u32.png}
		\caption{XOR u32}
		\label{fig:tiempo-verify-xor-u32}
	\end{minipage}
	
	\caption{Mediciones de tiempos para el comando \textbf{verify} para todas las familias de programas de Noir}
	\label{fig:verify_tiempos}
\end{figure}


\begin{figure}[htbp!]
	\centering
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Assert Zero.png}
		\caption{AssertZero}
		\label{fig:tamanio-vk-assert-zero}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Memoria (varía operaciones).png}
		\caption{Memoria (op)}
		\label{fig:tamanio-vk-mem}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Memoria (varía tamaño de lista).png}
		\caption{Memoria (tamaño)}
		\label{fig:tamanio-vk-mem-wide}
	\end{minipage}
	
	\vspace{0.5cm} 
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Range-u8.png}
		\caption{Range u8}
		\label{fig:tamanio-vk-range-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Range-u16.png}
		\caption{Range u16}
		\label{fig:tamanio-vk-range-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Range-u32.png}
		\caption{Range u32}
		\label{fig:tamanio-vk-range-u32}
	\end{minipage}
	
	\vspace{0.5cm}  
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Xor-u8.png}
		\caption{XOR u8}
		\label{fig:tamanio-vk-xor-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Xor-u16.png}
		\caption{XOR u16}
		\label{fig:tamanio-vk-xor-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-write_vk-Xor-u32.png}
		\caption{XOR u32}
		\label{fig:tamanio-vk-xor-u32}
	\end{minipage}
	
	\caption{Tamaño de la Verification Key para todas las familias de programas de Noir}
	\label{fig:tamanios-vk}
\end{figure}


\begin{figure}[htbp!]
	\centering
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Assert Zero.png}
		\caption{AssertZero}
		\label{fig:tamanio-prueba-assert-zero}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Memoria (varía operaciones).png}
		\caption{Memoria (op)}
		\label{fig:tamanio-prueba-mem}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Memoria (varía tamaño de lista).png}
		\caption{Memoria (tamaño)}
		\label{fig:tamanio-prueba-mem-wide}
	\end{minipage}
	
	\vspace{0.5cm} 
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Range-u8.png}
		\caption{Range u8}
		\label{fig:tamanio-prueba-range-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Range-u16.png}
		\caption{Range u16}
		\label{fig:tamanio-prueba-range-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Range-u32.png}
		\caption{Range u32}
		\label{fig:tamanio-prueba-range-u32}
	\end{minipage}
	
	\vspace{0.5cm}  
	
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Xor-u8.png}
		\caption{XOR u8}
		\label{fig:tamanio-prueba-xor-u8}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Xor-u16.png}
		\caption{XOR u16}
		\label{fig:tamanio-prueba-xor-u16}
	\end{minipage}%
	\begin{minipage}[b]{0.33\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imagenes/tamanios/tamanio-prove-Xor-u32.png}
		\caption{XOR u32}
		\label{fig:tamanio-prueba-xor-u32}
	\end{minipage}
	
	\caption{Tamaño de la prueba para todas las familias de programas de Noir}
	\label{fig:tamanios-prueba}
\end{figure}

\chapter{Protocolo para la matriz V}\label{sec:apendice_matriz_v}

Para completar el protocolo tenemos que hablar sobre cómo demostramos la segunda propiedad de validez de la matriz $T$ respecto a un programa dado por $Q$ y $V$, es decir
$$\forall i,j,k,l,~~~ V_{i,j} = V_{k,l} \implies T_{i,j} = T_{k,l}$$
Para esto vamos a usar la idea de \textbf{permutación}. Una permutación es un ordenamiento de un conjunto, denotado con $\sigma$. Dado un conjunto $A = \{a_i\}_{0\leq i < n}$, definimos a un ordenamiento como una función biyectiva $\sigma: A \rightarrow A$. 

En nuestro caso particular, queremos una permutación sobre el conjunto de posiciones de la traza $T$, es decir, los pares 
$$I = \{(i,j) ~|~ 0 \leq i < N ~ \land ~ 0 \leq j < 3\}$$
Llamamos $T_{i,j}$ al valor de la matriz $T$ en la posición $(i,j)$, y lo mismo para la matriz $V$. De la matriz $V$ podemos obtener una permutación $\sigma$ donde $\sigma((i,j))$ es igual al par de índices de la \textbf{siguiente} ocurrencia del valor $V_{i,j}$. Si en la posición $(i,j)$ está la última ocurrencia de $V_{i,j}$ en $V$, $\sigma((i,j))$ es igual al par de índices de la primera aparición de $V_{i,j}$.

Veamos un ejemplo. La tabla $V$ de la figura \ref{tab:matriz_v} induce una permutación tal que 
\begin{itemize}
	\item $\textcolor{black}{\sigma((0,0)) = (0,0)}$ 
	\item$\textcolor{black}{\sigma((0,1)) = (1,1), ~\sigma((1,1)) = (0,1)}$
	\item$\sigma((0,2)) = (1,0), ~\sigma((1,0)) = (0,2)$
	\item$\textcolor{black}{\sigma((1,2)) = (2,0), ~\sigma((2,0)) = (1,2)}$
	\item$\textcolor{black}{\sigma((2,2)) = (2,2)}$    
\end{itemize}
En otras palabras, vemos que una permutación forma \textbf{ciclos} dentro de un conjunto. 

La restricción que establecida por la matriz $V$ es equivalente a decir que 
$$T_{i,j} = T_{\sigma((i,j))} ~~~ \forall (i,j)\in I$$
y esto a su vez equivale a decir que los conjuntos 
$$A = \{((i,j), T_{i,j}) ~ | ~ (i,j)\in I\}$$
$$B = \{(\sigma((i,j)), T_{i,j}) ~ | ~ (i,j)\in I\}$$
son iguales. En otras palabras, $T_{i,j} = T_{\sigma((i,j))} \Leftrightarrow A = B$. La demostración de esto es por absurdo en ambas direcciones. La pregunta entonces es ¿cómo podemos reducir la verificación $A=B$ a ecuaciones polinomiales?

\subsubsection{\textbf{Igualdad de conjuntos}}
Si quisiéramos demostrar que dos conjuntos arbitrarios $A = \{a_i\}_{0\leq i<k}$ y $B = \{b_i\}_{0\leq i<k}$ son iguales, podemos multiplicar todos sus elementos y ver si el producto de cada conjunto es el mismo. Sin embargo, vemos como esto se rompe para los conjuntos $\{3,4\}$ y $\{2,6\}$, donde el producto de los elementos de ambos es $12$ y sin embargo no son iguales. Pero esto no ocurriría si se tratara de conjuntos de polinomios irreducibles, debido a su factorización única.

Entonces tomemos ahora los conjuntos $A' = \{x+a_i\}_{0\leq i<k} \subset \Fp[x]$ y $B' = \{x+b_i\}_{0\leq i<k} \subset \Fp[x]$ construidos a partir de $A$ y $B$ respectivamente. En el ejemplo anterior, pasaríamos a tener los conjuntos de polinomios $\{x+3,x+4\}$ y $\{x+2,x+6\}$ y los productos ya serían distintos. Con esta construcción, $A=B \Leftrightarrow A'= B'$.

El truco consiste en usar el lema de Schwartz-Zippel trabajado en la sección \ref{sec:zippel}. Tomamos un $\gamma$ aleatorio (en el contexto de un protocolo, sería un challenge por parte del verifier que el prover no puede conocer de antemano) y computamos el producto de los polinomios de $A'$ y $B'$ evaluados en $\gamma$. Formalmente
$$\prod_{0 \leq i < k}(\gamma + a_i) = \prod_{0 \leq i < k}(\gamma + b_i) \Leftrightarrow A = B$$
con probabilidad altísima. Ahora, ¿cómo pasamos de esto a ecuaciones polinomiales? 

Sea $H = \{1, \omega, \omega^2, \cdots, \omega^{k-1}\}$ donde $\omega$ es una raíz de orden $k$, y sean $f$ y $g$ los polinomios que interpolan en el dominio $H$ a los valores $(a_0+\gamma, \cdots, a_{k-1} + \gamma)$ y $(b_0+\gamma, \cdots, b_{k-1} + \gamma)$ respectivamente. Decimos que $\prod_{0 \leq i < k}(\gamma + a_i) = \prod_{0 \leq i < k}(\gamma + b_i)$ si solo si existe un polinomio $Z$ tal que 
$$Z(\omega^0) = 1 ~~~ \land ~~~ Z(h)f(h) = g(h)Z(\omega h) ~~ \forall h \in H$$

Si tomamos a $Z$ como el polinomio que interpola en el dominio $H$ a los valores
$$(1, \frac{a_0 + \gamma}{b_0 + \gamma}, \frac{(a_0 + \gamma)(a_1 + \gamma)}{(b_0 + \gamma)(b_1 + \gamma)}, \cdots, \prod_{0\leq i < k-1}\frac{a_i+\gamma}{b_i+\gamma})$$
la propiedad se cumple en ambas direcciones.  

\chapter{FRI: Low Degree Proof}\label{sec:fri_ldp}

Vamos a contar resumidamente cómo se realiza una \textit{Low Degree Proof} sobre un polinomio. La idea es demostrar que un polinomio $p \in \Fp[X]$ tiene un grado $deg(p) < N$. En particular, lo que va a demostrar este protocolo es que tiene un grado $deg(p) \in [\frac{N}{2}, N)$, para algún $N = 2^n$. La idea del protocolo va a ser reducir a la mitad (redondeando para abajo) el grado del polinomio sucesivas veces, mientras prover y verifier interactúan, para que el verifier se convenza de que una serie de puntos pertenecen a un polinomio de grado acotado. 

Vamos a comenzar definiendo un \textit{blowup factor} $b$, una medida del grado de seguridad del protocolo. A partir de este valor, vamos a calcular 
$$m = n + b$$ y finalmente $$M = 2^m = 2 ^{n+b}$$
El prover a tomar un generador $\omega$ de $\Fp$ de grado $M$ para armar un dominio

$$D=[\omega^i : 0 \leq i < M] = [1, \omega, \omega^2, ..., \omega^{M-1}]$$

\noindent y va a evaluar $p$ en todos los puntos del dominio, obteniendo así 
$$P = [p(1), p(\omega), p(\omega^2), ..., p(\omega^{M-1})]$$

A continuación, va a armar un Merkle Tree con esos puntos y obtener el Merkle Root. Este va a ser pasado al verifier como Commit de la lista obtenida. Esto mismo va a repetirse en varias iteraciones, cada vez con un dominio de la mitad de tamaño y un polinomio de la mitad de tamaño. Para facilitar la explicación podemos pensar que el prover va a ir dándole oráculos de ciertos polinomios al verifier, aunque ahora sabemos que estos oráculos están implementados como merkle trees. 

Lo siguiente que va a ocurrir es una reducción sucesiva del grado del polinomio: en cada iteración este va a reducirse a la mitad. La estrategia para hacer esto va a ser armar 2 polinomios de grado $\lfloor \frac{d}{2} \rfloor$ siendo $d$ el grado actual del polinomio y realizar una combinación lineal entre ellos. Uno de estos polinomios va a ser armado con todos los términos impares del polinomio original, y el otro con todos los términos pares. Sea:
 
$$p_i(x)= a_0 + a_1 \cdot x + a_2 \cdot x^2 + \cdots +  a_d \cdot x^d$$
vamos a armar 2 polinomios

$$p_{i, par}(x) = a_0 + a_2 \cdot x + \cdots + a_d \cdot x^{\frac{d}{2}}$$ y

$$p_{i,impar}(x) = a_1 + a_3 \cdot x +\cdots + a_{d-1} \cdot x^{\lfloor\frac{d-1}{2}\rfloor}$$

de manera tal que se cumple la igualdad 
$$p_i(x) = p_{i,par}(x^2) + x \cdot p_{i,impar}(x^2)$$

Para obtener el siguiente polinomio de la siguiente iteración (de grado $\lfloor \frac{d}{2} \rfloor$) vamos a tomar 
$$p_{i+1} = p_{i,par} + \gamma \cdot p_{i,impar}$$
donde $\gamma$ es un \textit{challenge} por parte del verifier que el prover no puede saber de antemano. El dominio $D_{i+1}$ con el cual vamos a crear el nuevo Merkle Tree ahora está dado por $D^2$, es decir 
$$[1, \omega^2, \omega^4, ..., \omega^{2(M-1)}]$$
Al elevar todos los elementos de $D$ al cuadrado, obtendremos un dominio de la mitad de tamaño porque la mitad de los valores se repiten, dado que $\omega$ es una raíz de la unidad. 

Notemos también la siguiente igualdad:
$$p_i(-x) = p_{i,par}(x^2) - x \cdot p_{i,impar}(x^2)$$
Esto hace que el verifier pueda obtener $p_{i, par}$ y $p_{i, impar}$ a partir de $p$ con las ecuaciones
$$p_{par}(x^2) = \frac{p(x) + p(-x)}{2}$$ y 
$$p_{impar}(x^2) = \frac{p(x) - p(-x)}{2x}$$
y con ellas verificar a través de los oráculos que el oráculo de la siguiente iteracción se corresponde con una reducción correcta. Si aplicamos $n$ iteraciones, finalmente vamos a alcanzar una lista de $2^b$ elementos iguales, ya que se corresponden con evaluaciones de un polinomio constante. El verifier puede abrir esta lista en varios puntos aleatorios para convencerse probabilísticamente de que todos los elementos son iguales. Llegado este punto, la conclusión a la que llega el verifier es que el polinomio original tuvo que haber sido de grado a lo sumo $N-1$. 

%%%% BIBLIOGRAFIA
\newpage
\bibliographystyle{unsrt}
\bibliography{bibliografia.bib}

\end{document}
